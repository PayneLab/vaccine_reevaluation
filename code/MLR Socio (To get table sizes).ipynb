{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model, preprocessing\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cols(df, col, delim=\":\"):\n",
    "    split = col.split(delim)\n",
    "\n",
    "    df[split] = df[col].str.split(delim, expand=True)\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "    df['Country'] = df['Country'].str.strip()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLR(df, response_var, explanatory_vars):\n",
    "    '''\n",
    "    Parameters:\n",
    "        df: DataFrame containing the full dataset including response_var and explanatory_vars\n",
    "        response_var: (String) the name of the column containing the response variable for MLR\n",
    "        explanatory_vars: (list/iterable of strings) contains the names of the features to explore with MLR\n",
    "\n",
    "    Returns:\n",
    "        regr: a LinearRegression model from sklearn that is a fit model to the data provided in df.\n",
    "            It contains useful information as member variables that may be worth exploring\n",
    "        model: a statsmodel Multiple Linear regression model fit to the data provided in df.\n",
    "            It contains much of the same information as sklearn does, but in a more \"R-centric\" format\n",
    "            that can be more statistically intuitive\n",
    "        predictions: a statsmodel object based on 'model' that shows what the model would predict the\n",
    "            response_var to be in any given row and can be used to predict the response_var on new data that\n",
    "            may not contain the response_var\n",
    "    '''\n",
    "    x_and_y_cols = explanatory_vars.copy()\n",
    "    x_and_y_cols.append('MDG_0000000001')\n",
    "    df_no_nan = df[x_and_y_cols].copy().dropna()\n",
    "    X = df_no_nan[explanatory_vars]  # Our multiple variables\n",
    "    Y = df_no_nan['MDG_0000000001']\n",
    "\n",
    "    print(df_no_nan)\n",
    "    print(len(X))\n",
    "    print(len(Y))\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(X, Y)\n",
    "\n",
    "    print(\"MLR Results using Sci-kit Learn:\")\n",
    "    print('Intercept: \\n', regr.intercept_)\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "    print()\n",
    "\n",
    "    # with statsmodels\n",
    "    X = sm.add_constant(X)  # adding a constant\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return regr, model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(who_usa):\n",
    "    who_max_scaled = who_usa.copy()\n",
    "    for column in who_max_scaled.columns:\n",
    "        who_max_scaled[column] = who_max_scaled[column]  / who_max_scaled[column].abs().max()\n",
    "    return who_max_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlrSocio():\n",
    "    who = pd.read_csv(\"../data/WHO-SIMPLE.csv\")\n",
    "    who = split_cols(who, 'Country_Year', delim='_')\n",
    "    who['Year'] = who['Year'].astype(int)\n",
    "\n",
    "    # Get description of df values\n",
    "    print(\"Rows: \" + str(who.shape[0]) + \"\\n\", \"Columns: \" + str(who.shape[1] - 3) + \"\\n\",\n",
    "          \"Countries: \" + str(who['Country Code'].nunique()) + \"\\n\", \"Years: \" + str(who['Year'].nunique()))\n",
    "    \n",
    "    del who['Country']\n",
    "    del who['Country Code']\n",
    "    del who['WHS4_100']\n",
    "    del who['WHS4_117']\n",
    "    del who['WHS4_129']\n",
    "    del who['WHS4_544']\n",
    "    del who['WHS8_110']\n",
    "    del who['MCV2']\n",
    "    del who['LBW_NUMBER']\n",
    "    del who['MDG_0000000025']\n",
    "\n",
    "    #print(\"Rows: \" + str(who.shape[0]) + \"\\n\", \"Columns: \" + str(who.shape[1] - 3) + \"\\n\",\n",
    "          #\"Countries: \" + str(who['Country Code'].nunique()) + \"\\n\", \"Years: \" + str(who['Year'].nunique()))\n",
    "\n",
    "    who = normalize(who)\n",
    "    \n",
    "    #Include Socioeconmic factors that allow us to have over 1000 total observations\n",
    "    explanatory_vars = [ 'LBW_PREVALENCE', 'MDG_0000000026',\n",
    "                       'WSH_SANITATION_SAFELY_MANAGED', 'GHED_CHEGDP_SHA2011', 'GDP', 'MDG_0000000003']\n",
    "    response_var = 'MDG_0000000001'\n",
    "\n",
    "    MLR(who, response_var, explanatory_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 11289\n",
      " Columns: 34\n",
      " Countries: 191\n",
      " Years: 70\n",
      "       LBW_PREVALENCE  MDG_0000000026  WSH_SANITATION_SAFELY_MANAGED  \\\n",
      "120          0.135359        0.009274                       0.386102   \n",
      "122          0.132597        0.008468                       0.382540   \n",
      "123          0.132597        0.008468                       0.380889   \n",
      "124          0.132597        0.007258                       0.379302   \n",
      "125          0.132597        0.008871                       0.378189   \n",
      "126          0.129834        0.007258                       0.377165   \n",
      "127          0.129834        0.007661                       0.376223   \n",
      "128          0.129834        0.008065                       0.379353   \n",
      "129          0.129834        0.008065                       0.382934   \n",
      "130          0.129834        0.008468                       0.386400   \n",
      "131          0.127072        0.008871                       0.389748   \n",
      "132          0.127072        0.006855                       0.392981   \n",
      "133          0.127072        0.006452                       0.395975   \n",
      "134          0.127072        0.006452                       0.398325   \n",
      "135          0.127072        0.006048                       0.398403   \n",
      "215          0.359116        0.002419                       0.896234   \n",
      "216          0.359116        0.002419                       0.896234   \n",
      "217          0.359116        0.002016                       0.900394   \n",
      "218          0.356354        0.002016                       0.904555   \n",
      "219          0.356354        0.002016                       0.908715   \n",
      "220          0.356354        0.002016                       0.912875   \n",
      "221          0.356354        0.001613                       0.917036   \n",
      "222          0.353591        0.001613                       0.921196   \n",
      "223          0.353591        0.001613                       0.925357   \n",
      "224          0.353591        0.001613                       0.929517   \n",
      "310          0.226519        0.017339                       0.473684   \n",
      "311          0.220994        0.016935                       0.474826   \n",
      "312          0.215470        0.015726                       0.475900   \n",
      "313          0.212707        0.015323                       0.476946   \n",
      "314          0.209945        0.014516                       0.477987   \n",
      "...               ...             ...                            ...   \n",
      "10528        0.143646        0.010887                       0.481720   \n",
      "10529        0.143646        0.010081                       0.509250   \n",
      "10530        0.146409        0.009274                       0.536597   \n",
      "10531        0.149171        0.009677                       0.563761   \n",
      "10532        0.149171        0.009274                       0.590456   \n",
      "10533        0.151934        0.009677                       0.616391   \n",
      "10659        0.207182        0.004839                       0.881928   \n",
      "10660        0.212707        0.005242                       0.883073   \n",
      "10661        0.218232        0.005242                       0.884213   \n",
      "10662        0.220994        0.005242                       0.885351   \n",
      "10663        0.223757        0.005242                       0.886491   \n",
      "10664        0.226519        0.005242                       0.887622   \n",
      "10665        0.226519        0.005645                       0.888755   \n",
      "10666        0.226519        0.005645                       0.889886   \n",
      "10667        0.226519        0.005645                       0.891015   \n",
      "10668        0.226519        0.006048                       0.892142   \n",
      "10669        0.223757        0.006048                       0.893264   \n",
      "10670        0.223757        0.006048                       0.894405   \n",
      "10671        0.223757        0.006452                       0.895557   \n",
      "10672        0.220994        0.006452                       0.896725   \n",
      "10673        0.220994        0.006452                       0.897907   \n",
      "10674        0.220994        0.007258                       0.898483   \n",
      "10843        0.243094        0.045565                       0.284897   \n",
      "10844        0.240331        0.045968                       0.280713   \n",
      "10845        0.237569        0.045968                       0.276545   \n",
      "10846        0.237569        0.046774                       0.272394   \n",
      "10847        0.234807        0.047984                       0.268200   \n",
      "10848        0.234807        0.047177                       0.261848   \n",
      "10849        0.234807        0.046774                       0.255496   \n",
      "10850        0.237569        0.046774                       0.249144   \n",
      "\n",
      "       GHED_CHEGDP_SHA2011       GDP  MDG_0000000003  MDG_0000000001  \n",
      "120               0.144081  0.000162        0.075109        0.086174  \n",
      "122               0.137704  0.000203        0.060262        0.077458  \n",
      "123               0.140694  0.000262        0.069432        0.072961  \n",
      "124               0.134914  0.000335        0.093450        0.068329  \n",
      "125               0.126345  0.000376        0.088210        0.063746  \n",
      "126               0.119769  0.000415        0.077293        0.059161  \n",
      "127               0.125947  0.000498        0.073799        0.054683  \n",
      "128               0.102431  0.000601        0.080349        0.050338  \n",
      "129               0.091670  0.000562        0.082969        0.046180  \n",
      "130               0.094659  0.000556        0.084716        0.042295  \n",
      "131               0.095656  0.000601        0.089520        0.038708  \n",
      "132               0.100837  0.000575        0.091266        0.035626  \n",
      "133               0.107413  0.000596        0.089083        0.033199  \n",
      "134               0.109605  0.000617        0.095633        0.031488  \n",
      "135               0.097648  0.000531        0.088210        0.030428  \n",
      "215               0.047230  0.004868        0.100437        0.034441  \n",
      "216               0.049422  0.004820        0.086900        0.033485  \n",
      "217               0.054205  0.005124        0.088646        0.032565  \n",
      "218               0.052810  0.005802        0.094760        0.031661  \n",
      "219               0.049024  0.006897        0.095633        0.030725  \n",
      "220               0.046234  0.008427        0.151965        0.029792  \n",
      "221               0.046433  0.010363        0.144541        0.028915  \n",
      "222               0.051216  0.012033        0.148035        0.028105  \n",
      "223               0.058390  0.014719        0.141048        0.027342  \n",
      "224               0.080709  0.011830        0.149345        0.026613  \n",
      "310               0.083699  0.000089        0.137991        0.096609  \n",
      "311               0.092666  0.000099        0.120524        0.092231  \n",
      "312               0.151654  0.000111        0.120524        0.087968  \n",
      "313               0.143085  0.000131        0.125328        0.083869  \n",
      "314               0.120765  0.000167        0.126201        0.079851  \n",
      "...                    ...       ...             ...             ...  \n",
      "10528             0.131726  0.005464        0.136245        0.037830  \n",
      "10529             0.135711  0.006346        0.125764        0.036020  \n",
      "10530             0.135911  0.007612        0.122707        0.034285  \n",
      "10531             0.141889  0.008201        0.124454        0.032725  \n",
      "10532             0.138302  0.008553        0.118777        0.031344  \n",
      "10533             0.143284  0.006229        0.113974        0.030124  \n",
      "10659             0.249900  0.478339        0.208297        0.025439  \n",
      "10660             0.263452  0.493711        0.196507        0.025116  \n",
      "10661             0.279195  0.510255        0.186026        0.024845  \n",
      "10662             0.289358  0.534602        0.179476        0.024603  \n",
      "10663             0.291152  0.569850        0.176856        0.024373  \n",
      "10664             0.291152  0.608244        0.173362        0.024122  \n",
      "10665             0.292945  0.644542        0.179476        0.023839  \n",
      "10666             0.297330  0.674274        0.181223        0.023512  \n",
      "10667             0.304703  0.686450        0.175546        0.023139  \n",
      "10668             0.324432  0.674137        0.165502        0.022733  \n",
      "10669             0.325827  0.699477        0.149345        0.022325  \n",
      "10670             0.324831  0.725163        0.136681        0.021937  \n",
      "10671             0.324631  0.755696        0.128384        0.021591  \n",
      "10672             0.323037  0.783123        0.115721        0.021290  \n",
      "10673             0.327023  0.817757        0.105677        0.021033  \n",
      "10674             0.333001  0.850302        0.097380        0.020810  \n",
      "10843             0.120765  0.006789        0.398690        0.056606  \n",
      "10844             0.161419  0.008560        0.396943        0.054904  \n",
      "10845             0.155042  0.010748        0.395197        0.053574  \n",
      "10846             0.127740  0.014741        0.392576        0.052727  \n",
      "10847             0.150458  0.015387        0.390393        0.052399  \n",
      "10848             0.136110  0.018345        0.388210        0.052443  \n",
      "10849             0.143085  0.014766        0.415721        0.052719  \n",
      "10850             0.128537  0.017789        0.412664        0.053233  \n",
      "\n",
      "[1021 rows x 7 columns]\n",
      "1021\n",
      "1021\n",
      "MLR Results using Sci-kit Learn:\n",
      "Intercept: \n",
      " 0.04869322496910912\n",
      "Coefficients: \n",
      " [ 0.08739421  0.51516489 -0.04211204 -0.08995078  0.01757879  0.01601361]\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         MDG_0000000001   R-squared:                       0.933\n",
      "Model:                            OLS   Adj. R-squared:                  0.933\n",
      "Method:                 Least Squares   F-statistic:                     2354.\n",
      "Date:                Thu, 01 Apr 2021   Prob (F-statistic):               0.00\n",
      "Time:                        21:54:39   Log-Likelihood:                 2923.7\n",
      "No. Observations:                1021   AIC:                            -5833.\n",
      "Df Residuals:                    1014   BIC:                            -5799.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "const                             0.0487      0.003     17.700      0.000       0.043       0.054\n",
      "LBW_PREVALENCE                    0.0874      0.007     13.175      0.000       0.074       0.100\n",
      "MDG_0000000026                    0.5152      0.008     65.520      0.000       0.500       0.531\n",
      "WSH_SANITATION_SAFELY_MANAGED    -0.0421      0.002    -19.879      0.000      -0.046      -0.038\n",
      "GHED_CHEGDP_SHA2011              -0.0900      0.010     -8.604      0.000      -0.110      -0.069\n",
      "GDP                               0.0176      0.005      3.377      0.001       0.007       0.028\n",
      "MDG_0000000003                    0.0160      0.007      2.402      0.016       0.003       0.029\n",
      "==============================================================================\n",
      "Omnibus:                      221.994   Durbin-Watson:                   0.302\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1203.205\n",
      "Skew:                           0.884   Prob(JB):                    5.34e-262\n",
      "Kurtosis:                       8.015   Cond. No.                         34.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mlrSocio()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
